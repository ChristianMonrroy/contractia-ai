# ğŸ”„ GuÃ­a de MigraciÃ³n: Notebook â†’ Web Application

## ğŸ“‹ Objetivo
Esta guÃ­a explica cÃ³mo migrar tu cÃ³digo del notebook `AGENTE_IA_CONTRATOS_VS44_Prueba.ipynb` a la arquitectura web modular.

---

## ğŸ—ºï¸ Mapeo de Componentes

### Del Notebook â†’ A la Arquitectura Web

```
NOTEBOOK (Colab)                    â†’    WEB APPLICATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Celdas 1-2: Setup y autenticaciÃ³n   â†’    Dockerfile + env vars
Celda 3: Funciones de carga         â†’    contractia_core.py
Celdas 4-6: Procesamiento           â†’    contractia_core.py
Celda 7: AnÃ¡lisis LLM               â†’    contractia_core.py
Celda 8: GeneraciÃ³n de informes     â†’    contractia_core.py
Celda 9: EjecuciÃ³n principal        â†’    main.py (endpoints)
Outputs/prints                      â†’    app.py (Streamlit UI)
```

---

## ğŸ”§ Paso a Paso: MigraciÃ³n del CÃ³digo

### 1. AutenticaciÃ³n y ConfiguraciÃ³n

**ANTES (Notebook):**
```python
# Celda 1
NOMBRE_DEL_ARCHIVO_JSON = "agenteia-471917-d588639beeef.json"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = NOMBRE_DEL_ARCHIVO_JSON
```

**DESPUÃ‰S (Web App):**
```python
# backend/main.py
PROJECT_ID = os.getenv("GCP_PROJECT_ID", "agenteia-471917")
LOCATION = os.getenv("GCP_LOCATION", "us-central1")

# Las credenciales se inyectan automÃ¡ticamente en Cloud Run
```

---

### 2. InicializaciÃ³n de Vertex AI

**ANTES (Notebook):**
```python
# Celda 2
def configurar_entorno_vertexai():
    PROJECT_ID = "agenteia-471917"
    LOCATION = "us-central1"
    vertexai.init(project=PROJECT_ID, location=LOCATION)
```

**DESPUÃ‰S (Web App):**
```python
# backend/contractia_core.py
class ContractiaAgent:
    def __init__(self, model_name: str = "gemini-2.0-flash-exp"):
        vertexai.init(project=PROJECT_ID, location=LOCATION)
        self.llm = ChatVertexAI(model_name=model_name, temperature=0.0)
        self.embeddings = VertexAIEmbeddings(model_name="textembedding-gecko@latest")
```

---

### 3. Carga de Documentos

**ANTES (Notebook):**
```python
# Celda 3
def procesar_documentos_carpeta(folder_path):
    documentos_combinados = []
    for file_name in os.listdir(folder_path):
        if file_name.endswith('.pdf'):
            loader = PyPDFLoader(file_path)
            docs = loader.load()
            documentos_combinados.extend(docs)
    return documentos_combinados
```

**DESPUÃ‰S (Web App):**
```python
# backend/contractia_core.py
class ContractiaAgent:
    def cargar_documento(self, pdf_path: str) -> List[Document]:
        loader = PyPDFLoader(pdf_path)
        self.documentos = loader.load()
        return self.documentos

# backend/main.py
@app.post("/api/v1/upload-document")
async def upload_document(file: UploadFile = File(...)):
    # Guardar en Cloud Storage
    blob.upload_from_string(contents, content_type='application/pdf')
```

---

### 4. CreaciÃ³n de Vectorstore

**ANTES (Notebook):**
```python
# Celda 4
text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
splits = text_splitter.split_documents(documentos)
vectorstore = FAISS.from_documents(splits, embeddings)
```

**DESPUÃ‰S (Web App):**
```python
# backend/contractia_core.py
class ContractiaAgent:
    def crear_vectorstore(self, chunk_size: int = 2000, chunk_overlap: int = 200):
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        splits = text_splitter.split_documents(self.documentos)
        self.vectorstore = FAISS.from_documents(splits, self.embeddings)
        return self.vectorstore
```

---

### 5. AnÃ¡lisis de Referencias

**ANTES (Notebook):**
```python
# Celda 5
def extraer_referencias(texto):
    patrones = [r'[Cc]lÃ¡usula\s+\d+(?:\.\d+)*', ...]
    referencias = []
    for patron in patrones:
        matches = re.findall(patron, texto)
        referencias.extend(matches)
    return referencias

# Usar directamente
referencias = extraer_referencias(texto_documento)
```

**DESPUÃ‰S (Web App):**
```python
# backend/contractia_core.py
class ContractiaAgent:
    def extraer_referencias(self, texto: str) -> List[str]:
        patrones = [r'[Cc]lÃ¡usula\s+\d+(?:\.\d+)*', ...]
        referencias = []
        for patron in patrones:
            matches = re.findall(patron, texto)
            referencias.extend(matches)
        return list(set(referencias))
    
    def analizar_referencias_rotas(self) -> List[Dict]:
        texto_completo = "\n".join([doc.page_content for doc in self.documentos])
        todas_referencias = self.extraer_referencias(texto_completo)
        
        errores = []
        for ref in todas_referencias:
            validacion = self.validar_referencia(ref)
            if not validacion["existe"]:
                errores.append({...})
        
        return errores
```

---

### 6. EjecuciÃ³n Principal y Resultados

**ANTES (Notebook):**
```python
# Celda 9 - EjecuciÃ³n directa
if __name__ == "__main__":
    # Cargar docs
    documentos = procesar_documentos_carpeta("contratos/")
    
    # Crear vectorstore
    vectorstore = crear_vectorstore(documentos)
    
    # Analizar
    errores = analizar_referencias(documentos)
    
    # Mostrar resultados
    print(f"Errores encontrados: {len(errores)}")
    for error in errores:
        print(f"- {error}")
```

**DESPUÃ‰S (Web App):**

```python
# backend/main.py
@app.post("/api/v1/audit", response_model=AuditoriaResponse)
async def iniciar_auditoria(request: AuditoriaRequest, background_tasks: BackgroundTasks):
    auditoria_id = str(uuid.uuid4())
    
    # Iniciar procesamiento asÃ­ncrono
    background_tasks.add_task(
        procesar_auditoria,
        auditoria_id,
        request.document_id,
        request.tipo_analisis
    )
    
    return AuditoriaResponse(
        auditoria_id=auditoria_id,
        status="processing",
        fecha_inicio=datetime.now(),
        ...
    )

async def procesar_auditoria(auditoria_id: str, document_id: str, tipo_analisis: str):
    # Instanciar agente
    agente = ContractiaAgent()
    
    # Descargar de GCS
    pdf_path = await descargar_de_gcs(document_id)
    
    # Procesar
    agente.cargar_documento(pdf_path)
    agente.crear_vectorstore()
    resultados = agente.auditoria_completa()
    
    # Guardar resultados
    await guardar_resultados(auditoria_id, resultados)

# frontend/app.py (Streamlit)
if st.button("ğŸš€ Iniciar AuditorÃ­a"):
    resultado = iniciar_auditoria(document_id, tipo_analisis)
    st.success(f"AuditorÃ­a iniciada: {resultado['auditoria_id']}")
    
    # Mostrar progreso
    while estado := obtener_estado(resultado['auditoria_id']):
        if estado['status'] == 'completed':
            st.balloons()
            mostrar_resultados(estado['resultados'])
            break
        time.sleep(2)
```

---

## ğŸ”„ Checklist de MigraciÃ³n

### âœ… Backend
- [ ] Extraer funciones del notebook a `contractia_core.py`
- [ ] Crear clase `ContractiaAgent` con mÃ©todos organizados
- [ ] Implementar endpoints REST en `main.py`
- [ ] Configurar variables de entorno en lugar de hardcoded
- [ ] AÃ±adir manejo de errores y logging
- [ ] Implementar procesamiento asÃ­ncrono con BackgroundTasks
- [ ] Integrar con Cloud Storage para documentos
- [ ] AÃ±adir persistencia de resultados (Firestore/Cloud SQL)

### âœ… Frontend
- [ ] Crear interfaz de upload en Streamlit
- [ ] Implementar visualizaciÃ³n de resultados
- [ ] AÃ±adir grÃ¡ficos y mÃ©tricas
- [ ] Crear sistema de progreso en tiempo real
- [ ] Implementar descarga de informes
- [ ] AÃ±adir historial de auditorÃ­as

### âœ… Deployment
- [ ] Crear Dockerfile para backend
- [ ] Crear Dockerfile para frontend
- [ ] Configurar Cloud Run para ambos servicios
- [ ] Configurar Cloud Storage buckets
- [ ] Configurar IAM y permisos
- [ ] Implementar CI/CD con Cloud Build

---

## ğŸ“ Patrones de CÃ³digo

### PatrÃ³n 1: De funciÃ³n global a mÃ©todo de clase

**ANTES:**
```python
def analizar_documento(documento):
    # lÃ³gica
    return resultado
```

**DESPUÃ‰S:**
```python
class ContractiaAgent:
    def analizar_documento(self) -> Dict:
        # lÃ³gica usando self.documentos
        return resultado
```

### PatrÃ³n 2: De prints a logging

**ANTES:**
```python
print("âœ… Procesamiento completado")
print(f"Errores: {len(errores)}")
```

**DESPUÃ‰S:**
```python
import logging
logger = logging.getLogger(__name__)

logger.info("Procesamiento completado")
logger.info(f"Errores detectados: {len(errores)}")
```

### PatrÃ³n 3: De ejecuciÃ³n sÃ­ncrona a asÃ­ncrona

**ANTES:**
```python
def procesar():
    resultado = analizar_contrato()
    return resultado
```

**DESPUÃ‰S:**
```python
async def procesar():
    # Para operaciones I/O intensivas
    resultado = await analizar_contrato_async()
    return resultado

# O con BackgroundTasks para procesamiento largo
@app.post("/audit")
async def audit(background_tasks: BackgroundTasks):
    background_tasks.add_task(procesar_largo)
    return {"status": "processing"}
```

---

## ğŸ¯ Funciones Clave a Migrar

### Prioridad Alta (Core Functionality)
1. âœ… `cargar_documento()` â†’ Migrada a `ContractiaAgent.cargar_documento()`
2. âœ… `crear_vectorstore()` â†’ Migrada a `ContractiaAgent.crear_vectorstore()`
3. âœ… `extraer_referencias()` â†’ Migrada a `ContractiaAgent.extraer_referencias()`
4. âœ… `validar_referencia()` â†’ Migrada a `ContractiaAgent.validar_referencia()`
5. âš ï¸ `analizar_con_llm()` â†’ **PENDIENTE: Adaptar a mÃ©todo de clase**
6. âš ï¸ `generar_informe()` â†’ **PENDIENTE: Adaptar para markdown/PDF**

### Prioridad Media (Features Adicionales)
7. âš ï¸ `analizar_fechas()` â†’ **PENDIENTE: Implementar lÃ³gica completa**
8. âš ï¸ `analizar_montos()` â†’ **PENDIENTE: Implementar validaciones**
9. âš ï¸ `validar_normativa()` â†’ **PENDIENTE: Integrar documentos MEF**

### Prioridad Baja (Nice to Have)
10. âš ï¸ `chat_interactivo()` â†’ **OPCIONAL: Para versiÃ³n futura**
11. âš ï¸ `comparar_contratos()` â†’ **OPCIONAL: Feature avanzado**

---

## ğŸš¨ Consideraciones Importantes

### 1. Cambios en Manejo de Archivos

**NOTEBOOK:**
```python
# Archivos en /content/ de Colab
file_path = "/content/contratos/contrato.pdf"
```

**WEB APP:**
```python
# Archivos en Cloud Storage
file_url = "gs://contractia-documents/uploads/uuid/contrato.pdf"

# Descargar temporalmente para procesar
temp_path = await download_from_gcs(file_url)
```

### 2. Cambios en AutenticaciÃ³n

**NOTEBOOK:**
```python
# Archivo JSON subido manualmente
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "key.json"
```

**WEB APP:**
```python
# Credenciales inyectadas automÃ¡ticamente por Cloud Run
# No necesita configuraciÃ³n manual
```

### 3. Cambios en Outputs

**NOTEBOOK:**
```python
# Display directo en Jupyter
display(Markdown(informe))
```

**WEB APP:**
```python
# API retorna JSON
return JSONResponse(content={"informe": informe_md})

# Frontend renderiza
st.markdown(resultados['informe'])
```

---

## ğŸ§ª Testing Durante la MigraciÃ³n

### 1. Probar Funciones Individualmente
```python
# backend/test_contractia_core.py
import pytest
from contractia_core import ContractiaAgent

def test_extraer_referencias():
    agente = ContractiaAgent()
    texto = "Ver ClÃ¡usula 5.2 y Anexo B"
    referencias = agente.extraer_referencias(texto)
    assert "ClÃ¡usula 5.2" in referencias
    assert "Anexo B" in referencias

def test_cargar_documento():
    agente = ContractiaAgent()
    docs = agente.cargar_documento("test_contract.pdf")
    assert len(docs) > 0
```

### 2. Probar Endpoints
```python
# backend/test_main.py
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_upload_document():
    with open("test.pdf", "rb") as f:
        response = client.post(
            "/api/v1/upload-document",
            files={"file": ("test.pdf", f, "application/pdf")}
        )
    assert response.status_code == 200
    assert "document_id" in response.json()
```

---

## ğŸ“š Recursos Adicionales

- **FastAPI Docs:** https://fastapi.tiangolo.com/
- **Streamlit Docs:** https://docs.streamlit.io/
- **Cloud Run Docs:** https://cloud.google.com/run/docs
- **LangChain Docs:** https://python.langchain.com/

---

## â“ FAQ

**P: Â¿Puedo seguir usando el notebook en paralelo?**  
R: SÃ­, mantÃ©nlo para experimentaciÃ³n rÃ¡pida, pero la versiÃ³n web es la de producciÃ³n.

**P: Â¿CÃ³mo migro los prompts del LLM?**  
R: Extrae los prompts a archivos separados o a un mÃ³dulo `prompts.py` para mejor mantenimiento.

**P: Â¿Necesito cambiar el modelo de Gemini?**  
R: No, `gemini-2.0-flash-exp` funciona igual en Colab y Vertex AI.

**P: Â¿CÃ³mo manejo el procesamiento largo?**  
R: Usa BackgroundTasks de FastAPI o Cloud Tasks para procesamiento asÃ­ncrono.

---

**âœ… Una vez completada la migraciÃ³n, tendrÃ¡s:**
- Sistema escalable y en producciÃ³n
- API REST documentada automÃ¡ticamente
- Interfaz web profesional
- Deployment automatizado en GCP
- Monitoreo y logs centralizados
- Base para tu tesis y presentaciÃ³n

ğŸš€ **Â¡Adelante con la migraciÃ³n!**
